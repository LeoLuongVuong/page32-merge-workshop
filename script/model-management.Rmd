---
title: "Model Management - Working Notebook"
editor_options: 
  chunk_output_type: console
---

**NOTE: This `model-management.Rmd` file is meant to be a fluid "working
notebook"** for the Pharmacometrician to use throughout the project. Some points
to consider:

* This file is _not_ meant to "knit" to HTML or PDF.

* You do _not_ need to copy/paste code in here in order to preserve the story of
your modeling activities. Instead, re-use code chunks as needed, changing the
name of model as you iterate, and updating any specific pieces of code where
relevant.

* Attach notes, description, and other annotation to your model object as you go
(via `bbr`'s `add_notes()`, `add_description()`, etc.). **`bbr` will keep track
of this information for you. You do _not_ need to keep these calls (or the
associated notes) in this script to preserve them.**

* All notes, description, etc. can be accessed later by re-loading the specific
model, or by viewing them in the tibble returned from `run_log()`.


```{r setup}
library(bbr)
library(tidyverse)
library(here)
library(pmplots)
library(magrittr)

source(here("script/functions/bbr-helpers.R"))
source(here("script/functions/functions-diagnostics.R"))

# define model dir and load tags
MOD_DIR <- here("model", "pk")
spec_path <- here("data", "derived", "pk.yml")
spec <- yspec::load_spec(spec_path)

# Install bbi (once per user per project)
# bbr::use_bbi(.path = getOption("bbr.bbi_exe_path"))

# Initialize bbi (once per modeling directory)
# bbi_init(MOD_DIR, .nonmem_dir = "/opt/NONMEM", .nonmem_version = "nm75")
```


# 1 run log

```{r, eval=FALSE}
rl_cols <- c("run","description","based_on","ofv", "dofv", "aic","notes", "error_msg")
rl <- run_log(MOD_DIR) %>% 
  add_config() %>% suppressWarnings() %>%
  add_summary() %>%
  add_aic() %>%      # this is a custom function in script/functions/bbr-helpers.R
  add_dofv() %>%     # this is a custom function in script/functions/bbr-helpers.R
  collapse_to_string(notes) %>%
  select(c(all_of(rl_cols)), contains("has_changed"))

View(rl, "runlog")
```

# 2 create models

## model iteration

```{r, eval=FALSE}
PARENT_MODEL <- 102 # Name of most recently completed model
THIS_MODEL <- 103   # Name of new model to create (based on PARENT_MODEL)

set.seed(240321) # for reproducibility of tweak_param_estimates(), below

parent_mod <- read_model(file.path(MOD_DIR, PARENT_MODEL))

mod <- copy_model_from(
  .parent_mod=parent_mod, 
  .new_model=THIS_MODEL, # will increment, or pass custom name if desired
  # .overwrite = TRUE,   # uncomment this line to overwrite existing THIS_MODEL
) %>%
  update_model_id() %>%
  inherit_param_estimates() %>%
  tweak_initial_estimates()
```


```{r}
# compare control stream to parent model
model_diff(mod)
```


```{r}
# open file for editing in RStudio
open_model_file(mod) 
```

## add model annotation
Annotating your models as you work enhances traceability and reproduceability.
You do _not_ have to maintain the code for these model annotation calls; `bbr`
keeps track of all annotations for later reference. They can then be used in Run
Logs and other reporting outputs, as needed.

Also note that **these annotation functions can be run at any time, before or
after executing your model.**

Consider the following guidance:

* **`description`** is used to document the basic model structure. 
  * What you add here will be included in the final Run Log table. It should 
  "stand alone" to describe model structure. 
  * You will need to enter this _manually, for each new model_.

* **`notes`** are for informal notes on decision points, model performance, etc. 
  * These are for later reference by the modeler or collaborators, and will 
  _not_ be included in the final Run Log. 
  * Often, `notes` are used to describe notable changes from parent model. 

* **`star`** only your key models. 
  * Only starred models will be included in the final Run Log table in the report. 
  * You can use `add_star(mod)` or `remove_star(mod)` at any point in the 
  analysis process.
  
* **`tags`** are optional organizational helpers. 
  * These are often used to organize "categories" of models. 
  * You can easily filter a Run Log to only models with a given tag by using 
  `run_log(..., .include = "<my tag>")`.
  

```{r}
# preview the description of the parent model
print(parent_mod$description)
```

```{r}
# uncomment the next line and fill in description of new model 
#   to describe the basic model structure
# mod <- add_description(mod, parent_mod$description)
print(mod$description)
```


```{r}
# optionally, add notes or tags before executing
# mod <- mod %>% add_notes("<my note>")
# mod <- mod %>% add_tags("<my tag>")
```


# 3 execute model

## submit model

```{r}
submit_model(mod, .mode="local", .wait = FALSE) # or submit model to run on head node  
# submit_model(mod) # submit model to run on compute nodes (.mode = "sge" is the default)
```

## monitoring

```{r, eval = FALSE}
# check if run has finished
check_nonmem_finished(mod)
# wait_for_nonmem(mod) # optionally hold the R console until model finishes

# print head and tail of output files to R console
tail_lst(mod)
tail_output(mod)

# open .lst file to view in RStudio
build_path_from_model(mod, ".lst") %>% file.edit()

# open OUTPUT or PRDERR files to view in RStudio
open_file_if_exists(mod, "OUTPUT")
open_file_if_exists(mod, "PRDERR")
```


# 4 view run results

## model summary

```{r, eval=FALSE}
modsum <- model_summary(mod) 
print(modsum)
```

```{r, eval=FALSE}
# preview final parameter estimates
param_df <- param_estimates(modsum) 
View(param_df)
```

## ad-hoc diagnostics

```{r, eval=FALSE}
# join input data to output tables
df <- nm_join(mod) %>%
  dplyr::filter(EVID == 0) %>% # Filter to only observation records
  yspec::ys_add_factors(spec, .suffix = "") # Add factors to data set based on spec information
View(df)
```

```{r}
# make some simple diagnostic plots with MetrumRG's pmplots package
dv_pred(df, yname = "concentration (mg/L)")
dv_ipred(df, yname = "concentration (mg/L)")
npde_time(df)
```

```{r}
# add a covariate/ETA plot...

# point them in the direction of getting towards model 104
```



## render quick-look diagnostics 

```{r, eval=FALSE}
# Render diagnostics with a parameterized Rmd template
# * Pass the bbr model object and path to Rmd template file
# * This renders and HTML and returns the path
# * Pipe the HTML path directly to browseURL to pop open in browser
model_diagnostics(
    mod,
    template = here("script", "diagnostic-templates", "diagnostics-quick.Rmd")
  ) %>%
  browseURL()
```


## compare two models

```{r, eval=FALSE}
model_diff(mod) # compare to parent model
```


## add post-execution model annotation

These annotation functions can be run at any time, before or after executing 
or evaluating your model.

Review of relevant guidance from above:

* **`notes`** are for informal notes on decision points, model performance, etc. 
  * These are for later reference by the modeler or collaborators, and will 
  _not_ be included in the final Run Log. 
  * Often, `notes` are used to describe notable changes from parent model. 

* **`star`** only your key models. 
  * Only starred models will be included in the final Run Log table in the report. 
  * You can use `add_star(mod)` or `remove_star(mod)` at any point in the 
  analysis process.


```{r}
# uncomment to add any notes 
# * key decision points
# * notes on model performance
# * notable changes from parent model
# mod <- add_notes(mod, "<notes on new model>")

# IF this is a key model that we want to include in the report, 
#   uncomment the next line to add a "star" to it
# mod <- add_star(mod)
```

## render report-ready diagnostics


```{r, eval=FALSE}
# Render diagnostics with a parameterized Rmd template
# * This uses the "report-ready" diagnostics template
# * It uses the yspec YAML to pull information about covariates in the dataset
# * Optionally, it will write out individual PNG or PDF files for each figure
rmd_template_path <- here("script", "diagnostic-templates", "pk-diagnostics-template.Rmd")

# Define the specifics of your model or pass rendering options
# * All available options are listed at the top of the template
# * Use `file.edit(rmd_template_path)` to open the template in RStudio
modelSpecifics <- list(
  run_mrggsave = FALSE,     # switch to TRUE to write out individual PNGs for each figure
  yspec = here("data/derived/pk.yml"),      # The labels and units are pulled from this file
  contCov = c("AGE","WT","ALB","EGFR"),     # Categorical covariates to plot
  catCov = c("STUDY", "RF", "CP", "DOSE"),  # Continuous covariates to plot
  etas = c("ETA1//ETA-KA", "ETA2//ETA-V/F", "ETA3//ETA-CL/F") # Map ETAs to names with "<eta>//<name>" pmplots syntax
)

# pass the model object (or path), modelSpecifics and template locations to our
# helper function and pipe the output directly to browseURL to pop open the html
# version in new browser window
model_diagnostics(
    mod,
    .p = modelSpecifics,
    template = rmd_template_path
  ) %>%
  browseURL()
```


# 5 assorted utility code

## model submission

### run many models

```{r, eval=FALSE}
# this will overwrite previous run output from the specified models
mods_to_run <- 106:200
map(mods_to_run, ~read_model(file.path(MOD_DIR,.x))) %>% 
  submit_models(.bbi_args=list(overwrite=TRUE, parallel = TRUE, threads = 8))
```

## tags

### print all currently used tags

```{r}
run_log(MOD_DIR) %>% 
  pull(tags) %>% 
  unlist() %>% 
  unique() 
```

### apply tag to many models

```{r, eval=FALSE}
mods_to_tag <- 106:200
walk(mods_to_tag, ~read_model(file.path(MOD_DIR,.x)) %>% 
      add_tags("<my tag>"))
```

## open model files

### open many models in RStudio

```{r, eval=FALSE}
mods_to_open <- 106:200
walk(mods_to_open, ~read_model(file.path(MOD_DIR,.x)) %>% 
      open_model_file())
```
