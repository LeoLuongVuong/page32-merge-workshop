---
title: "Model Management - Working Notebook"
editor_options: 
  chunk_output_type: console
---

**NOTE: This `model-management.Rmd` file is meant to be a fluid "working
notebook"** for the Pharmacometrician to use throughout the project. Some points
to consider:

* This file is _not_ meant to "knit" to HTML or PDF.

* You do _not_ need to copy/paste code in here in order to preserve the story of
your modeling activities. Instead, re-use code chunks as needed, changing the
name of model as you iterate, and updating any specific pieces of code where
relevant.

* Attach notes, description, and other annotation to your model object as you go
(via `bbr`'s `add_notes()`, `add_description()`, etc.). **`bbr` will keep track
of this information for you. You do _not_ need to keep these calls (or the
associated notes) in this script to preserve them.**

* All notes, description, etc. can be accessed later by re-loading the specific
model, or by viewing them in the tibble returned from `run_log()`.


```{r setup}
library(bbr)
library(pmplots)
library(tidyverse)
library(here)
library(glue)

source(here("script/functions/bbr-helpers.R"))
source(here("script/functions/functions-diagnostics.R"))

# define model dir
modDir <- here("model", "pk")

# Install bbi (once per user per project)
# bbr::use_bbi(.path = getOption("bbr.bbi_exe_path"))

# Initialize bbi (once per modeling directory)
# bbi_init(modDir, .nonmem_dir = "/opt/NONMEM", .nonmem_version = "nm75")
```


# Introduction: first model

You will likely **only use this chunk once** to create your first model, 
then you can comment it out.

```{r}
mod <- new_model(file.path(modDir, 100)) # create bbr object from control stream on disk
mod <- add_description(mod, "one-compartment model")
open_model_file(mod) # open control stream for preview/editing in RStudio
```

Once you have run this block, **skip ahead to section "3 - execute model"** below.

As a reminder, **each subsequent time**, you will skip the chunk above and 
**start with the run log chunk**.

# 1 run log

```{r, eval=FALSE}
rl_cols <- c("run","description","based_on","ofv", "dofv", "aic","notes", "error_msg")
rl <- run_log(modDir) %>% 
  add_config() %>% suppressWarnings() %>%
  add_summary() %>%
  add_aic() %>%      # this is a custom function in script/functions/bbr-helpers.R
  add_dofv() %>%     # this is a custom function in script/functions/bbr-helpers.R
  collapse_to_string(notes) %>%
  select(c(all_of(rl_cols)), contains("has_changed"))

View(rl, "runlog")
```

# 2 create models

## model iteration

Create a new model, based on a "parent model" of your choice.

```{r, eval=FALSE}
PARENT_MODEL <- 100 # Name of parent model to copy from (typically, most recently completed model)
THIS_MODEL <- 101   # Name of new model to create (based on PARENT_MODEL)

set.seed(240625) # for reproducibility of tweak_param_estimates(), below

parent_mod <- read_model(file.path(modDir, PARENT_MODEL))

mod <- copy_model_from(
  .parent_mod=parent_mod, 
  .new_model=THIS_MODEL, # will increment, or pass custom name if desired
  # .overwrite = TRUE,   # uncomment to overwrite existing THIS_MODEL
) %>%
  update_model_id() 

# uncomment to inherit final estimates of parent as initial estimates of new model
# mod <- mod %>%
#   inherit_param_estimates() %>%
#   tweak_initial_estimates()
```

```{r}
# this is only for demo purposes... we're pretending you made these modifications manually
if (THIS_MODEL == 101) file.copy(here("model/demos/101.ctl"), modDir, overwrite = TRUE)
```

```{r}
# open file for editing in RStudio
open_model_file(mod)
```

```{r}
## compare control stream to parent model
model_diff(mod)
```


## add model annotation
Annotating your models as you work enhances traceability and reproduceability.
You do _not_ have to maintain the code for these model annotation calls; `bbr`
keeps track of all annotations for later reference. They can then be used in Run
Logs and other reporting outputs, as needed.

Also note that **these annotation functions can be run at any time, before or
after executing your model.**

Consider the following guidance:

* **`description`** is used to document the basic model structure. 
  * What you add here will be included in the final Run Log table. It should 
  "stand alone" to describe model structure. 
  * You will need to enter this _manually, for each new model_.

* **`notes`** are for informal notes on decision points, model performance, etc. 
  * These are for later reference by the modeler or collaborators, and will 
  _not_ be included in the final Run Log. 
  * Often, `notes` are used to describe notable changes from parent model. 

* **`star`** only your key models. 
  * Only starred models will be included in the final Run Log table in the report. 
  * You can use `add_star(mod)` or `remove_star(mod)` at any point in the 
  analysis process.
  
* **`tags`** are optional organizational helpers. 
  * These are often used to organize "categories" of models. 
  * You can easily filter a Run Log to only models with a given tag by using 
  `run_log(..., .include = "<my tag>")`.
  

```{r}
# preview the description of the parent model
print(parent_mod$description)
```

```{r}
# uncomment the next line and fill in description of new model 
#   to describe the basic model structure
#mod <- add_description(mod, "two-compartment model")
print(mod$description)
```


```{r}
# optionally, add notes or tags before executing
# mod <- mod %>% add_notes("added a 2nd cmpt")
# mod <- mod %>% add_tags("<my tag>")
```

# 3 execute model

## submit model

```{r}
submit_model(mod, .mode="local", .wait = FALSE) # or submit model to run on head node  
# submit_model(mod) # submit model to run on compute nodes (.mode = "sge" is the default)
```

## monitoring

```{r, eval = FALSE}
# check if run has finished
check_nonmem_finished(mod)

# print head and tail of output files to R console
tail_lst(mod)
tail_output(mod)

# open .lst file to view in RStudio
build_path_from_model(mod, ".lst") %>% file.edit()

# open OUTPUT or PRDERR files to view in RStudio
open_file_if_exists(mod, "OUTPUT")
open_file_if_exists(mod, "PRDERR")
```


# 4 view run results

## model summary

```{r, eval=FALSE}
modsum <- model_summary(mod) 
print(modsum)
```

```{r, eval=FALSE}
# preview final parameter estimates
param_df <- param_estimates(modsum) 
View(param_df)
```

## ad-hoc diagnostics

```{r, eval=FALSE}
# join input data to output tables
df <- nm_join(mod) %>%
  dplyr::filter(EVID == 0) # Filter to only observation records
# View(df)
```

Make some simple diagnostic plots with MetrumRG's `pmplots` package

```{r}
dv_pred(df)
dv_ipred(df)
cwres_pred(df)
cwres_time(df)
```

```{r}
wrap_eta_cont(
  df,
  x = c("WT", "ALB", "EGFR", "AGE"),
  y = "ETA3",
  scales = "free_x"
)
```

## render quick-look diagnostics 

```{r, eval=FALSE}
# Render diagnostics with a parameterized Rmd template
# * Pass the bbr model object and path to Rmd template file
# * This renders and HTML and returns the path
# * Pipe the HTML path directly to browseURL to pop open in browser
model_diagnostics(
    mod,
    #.p = list(contCov = c("WT", "ALB", "EGFR", "AGE")), # uncomment to plot ETAs vs cont. covariates
    template = here("script", "diagnostic-templates", "pk-diagnostics-quick.Rmd")
  ) %>%
  browseURL()
```


## compare two models

```{r}
mod_to_compare_name <- PARENT_MODEL # change this to compare to other models
print(glue("Comparing {THIS_MODEL} to {mod_to_compare_name}"))
```

```{r, eval=FALSE}
mod_to_compare <- read_model(file.path(modDir, mod_to_compare_name))
model_diff(mod, mod_to_compare, .viewer = TRUE) # compare control streams
```

```{r}
# compare parameter estimates and stderr
# * Note: this only makes sense if your THETAs, etc. are the same
#   in both models that you are comparing
param_estimates_diff(mod, mod_to_compare)
```


```{r}
# Check for model diagnostics and open if present, for comparison
path_to_compare <- glue("{modDir}/{mod_to_compare_name}/pk-diagnostics-quick-{mod_to_compare_name}.html")
if (file.exists(path_to_compare)) {
  browseURL(path_to_compare)
} else {
  message(glue("No diagnostics output found at {path_to_compare}"))
}
```


## add post-execution model annotation

These annotation functions can be run at any time, before or after executing 
or evaluating your model.

Review of relevant guidance from above:

* **`notes`** are for informal notes on decision points, model performance, etc. 
  * These are for later reference by the modeler or collaborators, and will 
  _not_ be included in the final Run Log. 
  * Often, `notes` are used to describe notable changes from parent model. 

* **`star`** only your key models. 
  * Only starred models will be included in the final Run Log table in the report. 
  * You can use `add_star(mod)` or `remove_star(mod)` at any point in the 
  analysis process.


```{r}
# uncomment to add any notes 
# * key decision points
# * notes on model performance
# * notable changes from parent model
# mod <- add_notes(mod, "<notes on new model>")

# IF this is a key model that we want to include in the report, 
#   uncomment the next line to add a "star" to it
# mod <- add_star(mod)
```

At this point, you may want to return to the "1 - run log" section to keep iterating on your model.

## render report-ready diagnostics

* This section uses the "report-ready" diagnostics template: `pk-diagnostics-report.Rmd`
* It uses the yspec YAML to pull information about covariates in the dataset
* Optionally, it will write out individual PNG or PDF files for each figure

```{r, eval=FALSE}
rmd_template_path <- here("script", "diagnostic-templates", "pk-diagnostics-report.Rmd")

# uncomment to open the Rmd template in RStudio
# file.edit(rmd_template_path)

# Define the specifics of your model or pass rendering options
# * All available options are listed at the top of the Rmd template
# * Any options _not_ specified here will use the default in the Rmd template
modelSpecifics <- list(
  run_mrggsave = FALSE,  # switch to TRUE to write out individual PNGs for each figure
  log_dv = FALSE,        # switch to TRUE if DV was estimated in the log domain
  eta_names = c(         # Map ETAs to names with "<eta>//<name>" pmplots syntax
    "ETA1//ETA-KA", 
    "ETA2//ETA-V/F", 
    "ETA3//ETA-CL/F"
  )
)

# pass the model object (or path), modelSpecifics and template locations to our
# helper function and pipe the output directly to browseURL to pop open the HTML
# version in new browser window
model_diagnostics(
    mod,
    .p = modelSpecifics,
    template = rmd_template_path
  ) %>%
  browseURL()
```

```{r}
# Check for report-ready diagnostics and open if present, for comparison
path_to_compare <- glue("{modDir}/{mod_to_compare_name}/pk-diagnostics-report-{mod_to_compare_name}.html")
if (file.exists(path_to_compare)) {
  browseURL(path_to_compare)
} else {
  message(glue("No diagnostics output found at {path_to_compare}"))
}
```

# 5 assorted utility code

## model submission

### run many models

```{r, eval=FALSE}
# this will overwrite previous run output from the specified models
mods_to_run <- 106:200
map(mods_to_run, ~read_model(file.path(modDir,.x))) %>% 
  submit_models(.bbi_args=list(overwrite=TRUE, parallel = TRUE, threads = 8))
```

## open model files

### open many models in RStudio

```{r, eval=FALSE}
mods_to_open <- 106:200
walk(mods_to_open, ~read_model(file.path(modDir,.x)) %>% 
      open_model_file())
```
